install.packages('tinytex')
setwd("C:/Users/Kaeleen/OneDrive/Documents/RPI/Data analytics Fall 2018/assignment 7/bank/bank")
bank_full <- read.csv("bank-full.csv",sep = ';')
bank_sample <- read.csv("bank.csv",sep = ';')
naColumns <- function(df) {
colnames(df)[unlist(lapply(df, function(x) any(is.na(x))))]
}
naColumns(bank_sample)
library('ggplot2')
library('dplyr')
library("gridExtra")
bankfullyes <-filter(bank_full, y == 'yes')
bankfullno <- filter(bank_full, y == 'no')
yesByAge <- ggplot(bankfullyes, aes(age)) + geom_histogram(binwidth = 5) + labs(title = "Term Deposits Yes Count by Age", x="age", y="Count of Yes")
noByAge <- ggplot(bankfullno, aes(age)) + geom_histogram(binwidth = 5) + labs(title = "Term Deposits No Count by Age", x="age", y="Count of No")
grid.arrange(yesByAge,noByAge,ncol=1)
##profession of the subscribers
ggplot(bank_full)+geom_histogram(aes(x=job, fill=y),stat = 'count')
## other variables
yByEducation <- ggplot(bank_full)+geom_histogram(aes(x=education, fill=y),stat = 'count')
yByMarital <- ggplot(bank_full)+geom_histogram(aes(x=marital, fill=y),stat = 'count')
yByDefault <- ggplot(bank_full)+geom_histogram(aes(x=default, fill=y),stat = 'count')
yByHousing <- ggplot(bank_full)+geom_histogram(aes(x=housing, fill=y),stat = 'count')
grid.arrange(yByEducation,yByMarital,yByDefault,yByHousing)
## Correlation Analysis
library(psych)
#pairs.panels(bank_full[,c(1:8,17)])
#pairs.panels(bank_full[,c(9:17)])
## data subsets
bank_sub <- bank_full[,c(1:4,7:9,12:16,17)]
## data transformation
bank_sub$age <- cut(bank_sub$age,c(1,20,40,60,100))
## sample data
library(caret)
sample <- createDataPartition(y=bank_sub$y,p=0.8,list = FALSE)
training <- bank_sub[sample,]
testing <- bank_sub[-sample,]
## Descison Tree
library(rpart)
library(rpart.plot)
library(rattle)
dt_model <- rpart(y~., data = training)
predict_dt<- predict(dt_model, testing, type = 'class')
table(predict_dt, testing$y)
prop.table(table(predict_dt, testing$y))
fancyRpartPlot(dt_model)
## support vector machine
library(e1071)
svm_model <- svm(y~., data = training, cost=1000, gamma=0.0001)
predict_svm <- predict(svm_model,testing[,-13])
table(predict_svm, testing$y)
prop.table(table(predict_svm, testing$y))
## random forest model
library(randomForest)
rf_model <- randomForest(y~., data = training)
importance(rf_model)
library(caret)
predict_rf <- predict(rf_model, testing)
confusionMatrix(predict_rf, testing$y)
setwd("C:/Users/Kaeleen/OneDrive/Documents/RPI/Data analytics Fall 2018/assignment 7/bank/bank")
bank_full <- read.csv("bank-full.csv",sep = ';')
rm(list = ls())
eq <- read.csv("cleanData.csv",header = T)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
eq <- read.csv("cleanData.csv",header = T)
eq$I_d
eq$I_D
View(eq)
colnames(eq)
names(eq)[names(eq) == "Ã¯..I_D"] <- "ID"
sum(is.na(eq))
eq %>%
summarise_all(funs(sum(is.na(.))))
library(dplyr)
eq %>%
summarise_all(funs(sum(is.na(.))))
library(naniar)
install.packages("naniar")
library(naniar)
vis_miss(eq)
gg_miss_upset(eq)
> eq %>%
+   summarise_all(funs(sum(is.na(.))))
eq %>%
summarise_all(funs(sum(is.na(.))))
eq %>%
select(everything()) %>%  # replace to your needs
summarise_all(funs(sum(is.na(.))))
summary(eq)
